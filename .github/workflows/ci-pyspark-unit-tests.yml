name: CI PySpark Unit Tests
on:
  pull_request:
    branches:
      - main
    paths:
      - src/**
  merge_group:
    types: [checks_requested]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Java 8
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '8'

      - name: Install Spark
        run: |
          wget -qO- https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz | tar xvz
          mv spark-3.5.0-bin-hadoop3 $HOME/spark

      - name: Install Hadoop
        run: |
          wget -qO- https://archive.apache.org/dist/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz | tar xvz
          mv hadoop-3.3.6 $HOME/hadoop

      - name: Install Delta Lake
        run: |
          mkdir -p $HOME/delta
          wget -qO $HOME/delta/delta-core_2.12-2.4.0.jar https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.4.0/delta-core_2.12-2.4.0.jar

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install Python Dependencies
        run: |
          poetry install

      - name: Run unit tests
        run: |
          poetry run pytest --html=test-results/report/index.html --cov=oel --cov-report html:test-results/coverage --verbose -s

      - name: Publish test results report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-report
          path: test-results/report

      - name: Publish coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: test-results/coverage
